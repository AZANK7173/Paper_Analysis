{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Profilling - Paper Themes from Digital Twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.read_csv(\"../State of Art 33708b985809439182238815f44e02d2 - Copy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Material Type</th>\n",
       "      <th>Link</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Responsible</th>\n",
       "      <th>Status</th>\n",
       "      <th>Created by</th>\n",
       "      <th>Created time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digital twin design for real-time monitoring -...</td>\n",
       "      <td>Academic</td>\n",
       "      <td>Technical paper</td>\n",
       "      <td>https://www.tandfonline.com/doi/full/10.1080/0...</td>\n",
       "      <td>Digital_twin, monitoring</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not started</td>\n",
       "      <td>Alex</td>\n",
       "      <td>October 18, 2022 2:38 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ieeexplore.ieee.org/document/9325551/</td>\n",
       "      <td>Academic</td>\n",
       "      <td>Technical paper</td>\n",
       "      <td>https://ieeexplore.ieee.org/stamp/stamp.jsp?tp...</td>\n",
       "      <td>Digital_twin, Healthcare, monitoring</td>\n",
       "      <td>Italy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not started</td>\n",
       "      <td>Alex</td>\n",
       "      <td>October 18, 2022 2:47 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Digital Twin: Values, Challenges and Enablers ...</td>\n",
       "      <td>Academic</td>\n",
       "      <td>Technical paper</td>\n",
       "      <td>https://ieeexplore.ieee.org/stamp/stamp.jsp?tp...</td>\n",
       "      <td>Digital_twin, Hybrid Analysis and Modeling, Ma...</td>\n",
       "      <td>Norway, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not started</td>\n",
       "      <td>Alex</td>\n",
       "      <td>October 18, 2022 2:58 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cyber-Physical Cloud Manufacturing Systems Wit...</td>\n",
       "      <td>Academic</td>\n",
       "      <td>Technical paper</td>\n",
       "      <td>https://ieeexplore.ieee.org/stamp/stamp.jsp?tp...</td>\n",
       "      <td>Digital_twin, MTconnect, cyberphysical cloud m...</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not started</td>\n",
       "      <td>Alex</td>\n",
       "      <td>October 18, 2022 3:04 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data‐driven physics‐based digital twins via a ...</td>\n",
       "      <td>Academic</td>\n",
       "      <td>Technical paper</td>\n",
       "      <td>https://onlinelibrary.wiley.com/doi/epdf/10.10...</td>\n",
       "      <td>Digital_twin, data-model fusion, reduced-order...</td>\n",
       "      <td>Switzerland, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not started</td>\n",
       "      <td>Alex</td>\n",
       "      <td>October 18, 2022 3:11 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name      Type  \\\n",
       "0  Digital twin design for real-time monitoring -...  Academic   \n",
       "1      https://ieeexplore.ieee.org/document/9325551/  Academic   \n",
       "2  Digital Twin: Values, Challenges and Enablers ...  Academic   \n",
       "3  Cyber-Physical Cloud Manufacturing Systems Wit...  Academic   \n",
       "4  Data‐driven physics‐based digital twins via a ...  Academic   \n",
       "\n",
       "     Material Type                                               Link  \\\n",
       "0  Technical paper  https://www.tandfonline.com/doi/full/10.1080/0...   \n",
       "1  Technical paper  https://ieeexplore.ieee.org/stamp/stamp.jsp?tp...   \n",
       "2  Technical paper  https://ieeexplore.ieee.org/stamp/stamp.jsp?tp...   \n",
       "3  Technical paper  https://ieeexplore.ieee.org/stamp/stamp.jsp?tp...   \n",
       "4  Technical paper  https://onlinelibrary.wiley.com/doi/epdf/10.10...   \n",
       "\n",
       "                                             Keyword  \\\n",
       "0                           Digital_twin, monitoring   \n",
       "1               Digital_twin, Healthcare, monitoring   \n",
       "2  Digital_twin, Hybrid Analysis and Modeling, Ma...   \n",
       "3  Digital_twin, MTconnect, cyberphysical cloud m...   \n",
       "4  Digital_twin, data-model fusion, reduced-order...   \n",
       "\n",
       "                      Country  Year Abstract  Responsible       Status  \\\n",
       "0                      Taiwan   NaN      NaN          NaN  Not started   \n",
       "1                       Italy   NaN      NaN          NaN  Not started   \n",
       "2       Norway, United States   NaN      NaN          NaN  Not started   \n",
       "3               United States   NaN      NaN          NaN  Not started   \n",
       "4  Switzerland, United States   NaN      NaN          NaN  Not started   \n",
       "\n",
       "  Created by              Created time  \n",
       "0       Alex  October 18, 2022 2:38 PM  \n",
       "1       Alex  October 18, 2022 2:47 PM  \n",
       "2       Alex  October 18, 2022 2:58 PM  \n",
       "3       Alex  October 18, 2022 3:04 PM  \n",
       "4       Alex  October 18, 2022 3:11 PM  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape and Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 405 entries, 0 to 404\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Name           403 non-null    object \n",
      " 1   Type           403 non-null    object \n",
      " 2   Material Type  402 non-null    object \n",
      " 3   Link           401 non-null    object \n",
      " 4   Keyword        397 non-null    object \n",
      " 5   Country        399 non-null    object \n",
      " 6   Year           333 non-null    float64\n",
      " 7   Abstract       333 non-null    object \n",
      " 8   Responsible    0 non-null      float64\n",
      " 9   Status         405 non-null    object \n",
      " 10  Created by     405 non-null    object \n",
      " 11  Created time   405 non-null    object \n",
      "dtypes: float64(2), object(10)\n",
      "memory usage: 38.1+ KB\n"
     ]
    }
   ],
   "source": [
    "papers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: \n",
    "* Not many Names, Types or Materials_Type missing\n",
    "* Responsible is useless for data gathering\n",
    "* If more that one country, comma separated string\n",
    "* Created By and Status will not be used for the Analysis (data about info gathering) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Type', 'Material Type', 'Link', 'Keyword', 'Country', 'Year',\n",
       "       'Abstract', 'Responsible', 'Status', 'Created by', 'Created time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uniqueness - Type\n",
    "\n",
    "papers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Academic', 'Industrial', 'Business', nan], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers['Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Academic      357\n",
       "Industrial     36\n",
       "Business       10\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: \n",
    "\n",
    "* Mostly all of them are Academic, since it was specified, let's drop the \"Business\" category later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Article              165\n",
       "Conference Paper     144\n",
       "Website               41\n",
       "Technical paper       21\n",
       "Review                17\n",
       "Book Chapter           5\n",
       "Report                 4\n",
       "Cumulative report      2\n",
       "Editorial              2\n",
       "Book                   1\n",
       "Name: Material Type, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uniqueness - Material Type\n",
    "\n",
    "papers['Material Type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: \n",
    "\n",
    "* Perhaps put together those with least frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uniqueness - Material Type\n",
    "\n",
    "papers[\"Keyword\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: \n",
    "* A lot of unique values, basically one for each paper, so it needs to be dealt with by using Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uniqueness - country\n",
    "\n",
    "papers[\"Country\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "China                           79\n",
       "Germany                         38\n",
       "Italy                           24\n",
       "United States                   21\n",
       "Russian Federation              19\n",
       "                                ..\n",
       "Australia, Belgium               1\n",
       "China, Mexico, United States     1\n",
       "Italy, Spain, Sweden             1\n",
       "China, United States             1\n",
       "Taiwan                           1\n",
       "Name: Country, Length: 105, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[\"Country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS:\n",
    "* Countries will need to be separated in order to sort them correctly\n",
    "* Perhaps create extra columns for adicional countries\n",
    "* Understand how to visualize this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021.0    128\n",
       "2022.0     74\n",
       "2020.0     67\n",
       "2019.0     49\n",
       "2018.0     13\n",
       "2023.0      1\n",
       "2017.0      1\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uniqueness - Year \n",
    "papers[\"Year\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: \n",
    "* A lot of Missing Values\n",
    "* Mostly recent papers\n",
    "* Can be droped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.duplicated().sum()\n",
    "\n",
    "# No duplicates BEFORE data cleaning (can change after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4286\n"
     ]
    }
   ],
   "source": [
    "not_null = papers.count().sum()\n",
    "print(not_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574\n"
     ]
    }
   ],
   "source": [
    "null = papers.isnull().sum().sum()\n",
    "print(null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4860\n"
     ]
    }
   ],
   "source": [
    "total = not_null + null\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completeness: 88.18930041152264%\n"
     ]
    }
   ],
   "source": [
    "completeness = not_null/total\n",
    "print(f\"completeness: {completeness*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS:\n",
    "* We might wanna do this again AFTER dropping columns you may not use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS SO FAR\n",
    "\n",
    "1. Drop columns: Link, Responsible, Status, Created By and Created Time\n",
    "2. Drop Business Category in Academic and them ignore the column\n",
    "3. In Material Type column, put minor categories in one big category called \"Others\" \n",
    "4. Drop the Year category as well since basically all of them are recent (thanks to the topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1,2 and 4 - Droping Columns that won't be used for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = papers.drop(columns=[\"Responsible\",\"Link\",\"Status\",\"Created by\",\"Created time\",\"Year\",\"Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Creating a category called others in order to group by the objects from \"Material Type\" that appear in smaller freqeuncies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the method replace accept list types, and as you can see below, the new values counts represent what is happening\n",
    "\n",
    "clean_df[\"Material Type\"].replace(\n",
    "    [\"Website\", \"Technical paper\", \"Review\", \"Book Chapter\", \"Report\", \"Cumulative report\", \n",
    "    \"Editorial\", \"Book\"], \"Others\", inplace=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Article             165\n",
       "Conference Paper    144\n",
       "Others               93\n",
       "Name: Material Type, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[\"Material Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there was only one Name with wrong name, this was corrected manually\n",
    "\n",
    "clean_df.iloc[1][\"Name\"] = 'Pervasive and Connected Digital Twins - A Vision for Digital Health'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name             object\n",
       "Material Type    object\n",
       "Keyword          object\n",
       "Country          object\n",
       "Abstract         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, every column is made up by categorical features. However, in order to procede with the profiling, we need to understand the nature of each column and think about how it should be treated and visualized:\n",
    "\n",
    "1. Name \n",
    "2. Material Type \n",
    "3. Keyword \n",
    "4. Country \n",
    "5. Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Profiling - automated profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce022efa095548f5b90aaaa29c170537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec636e0145fa4d1c99a024f3d7ba99ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae4b6fad97e430a9040fff915e07bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77dac77c60254e6b8d0952e31be455b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas_profiling as pp\n",
    "\n",
    "#create report in html \n",
    "\n",
    "profile = pp.ProfileReport(clean_df,title=\"Report HTML\")\n",
    "profile.to_file(\"profiling.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations from Pandas Profiling\n",
    "\n",
    "1. There are a lot of duplicated papers, that should be dropped\n",
    "2. In some of the strings, there are chinese characters, that need to be analised\n",
    "3. Only a few values are missing in the 4 main columns, the abstract, however, has 72 missing ones\n",
    "4. Name: min lenght = 3 ?\n",
    "5. Keyword: words separated by commas, it needs to be separated\n",
    "6. Country: min lenght = 2 ? And same problem as with the keywords\n",
    "7. Abstract: a lot of missing values, duplicated as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Duplicated Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicates \n",
    "clean_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape, a lot of values were dropped\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9686acff4cd49af8b5f21ed88aa92ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c32422f9a74b2189ae3217b9923d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25e29be5e1d40b5b5ee938eb908dd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ece350ab1d48bd88874b942b894611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rerun the profiling tool in order to check if all duplicates were dropped\n",
    "\n",
    "import pandas_profiling as pp\n",
    "\n",
    "profile = pp.ProfileReport(clean_df,title=\"Report HTML\")\n",
    "profile.to_file(\"profiling_duplicate.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Material Type</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Country</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>WareBee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>WareBee</td>\n",
       "      <td>Others</td>\n",
       "      <td>Digital_twin, Warehouse</td>\n",
       "      <td>UK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name Material Type                  Keyword Country Abstract\n",
       "34  WareBee           NaN                      NaN     NaN      NaN\n",
       "35  WareBee        Others  Digital_twin, Warehouse      UK      NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# even after dropping duplicated, by analysing the data displayed in the profiling, there are papers with the same Name\n",
    "# let's see them\n",
    "\n",
    "clean_df[clean_df[\"Name\"]==\"WareBee\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Material Type</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Country</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The connotation of digital twin, and the const...</td>\n",
       "      <td>Others</td>\n",
       "      <td>Digital Mapping, Digital_twin, Feasibility, Ma...</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>The connotation of digital twin, and the const...</td>\n",
       "      <td>Article</td>\n",
       "      <td>Agricultural robots, Application method, Cyber...</td>\n",
       "      <td>China</td>\n",
       "      <td>Digital twin (DT) technology provides a novel,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name Material Type  \\\n",
       "8    The connotation of digital twin, and the const...        Others   \n",
       "153  The connotation of digital twin, and the const...       Article   \n",
       "\n",
       "                                               Keyword Country  \\\n",
       "8    Digital Mapping, Digital_twin, Feasibility, Ma...   China   \n",
       "153  Agricultural robots, Application method, Cyber...   China   \n",
       "\n",
       "                                              Abstract  \n",
       "8                                                  NaN  \n",
       "153  Digital twin (DT) technology provides a novel,...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[clean_df[\"Name\"]==\"The connotation of digital twin, and the construction and application method of shop-floor digital twin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping this specific repeted rows \n",
    "clean_df.drop([8,34], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Material Type', 'Keyword', 'Country', 'Abstract'], dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data: Names, Material Type, Keyword and Country\n",
    "\n",
    "Since most nan values from Keyword and Country share their incompletness with Name and Material Type rowyse, we just need to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new df with not null keyword values\n",
    "df_not_nan = clean_df[clean_df[\"Keyword\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new df with not null Country values\n",
    "df_not_nan = df_not_nan[df_not_nan[\"Country\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 347 entries, 0 to 376\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Name           347 non-null    object\n",
      " 1   Material Type  347 non-null    object\n",
      " 2   Keyword        347 non-null    object\n",
      " 3   Country        347 non-null    object\n",
      " 4   Abstract       281 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 16.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_not_nan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the info, it only remains the null values from the abstract. Which will be dealt with later in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating weird values seen in Name and Country\n",
    "\n",
    "During the Proffiling, it was possible to see that some datapoints had strange lengths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intangles\n",
      "Altair\n",
      "MetaTwin\n",
      "Siemens\n",
      "IBM\n",
      "Oracle\n",
      "Braincube\n",
      "IoTwins\n",
      "WareBee\n",
      "Twinu\n",
      "ReLOG3P\n",
      "TonePedia\n",
      "Orbit GT\n",
      "AppsBow\n",
      "TWAICE\n",
      "Maplewell\n",
      "IBM DT\n",
      "SWIM EDX\n"
     ]
    }
   ],
   "source": [
    "names = list(df_not_nan[\"Name\"].unique())\n",
    "\n",
    "def print_small_lens(names, thresh = 10):\n",
    "    for name in names:\n",
    "        if len(name) < thresh:\n",
    "            print(name)\n",
    "\n",
    "print_small_lens(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is possible to see, some names are not very clear when it comes to specifying the research, but no wrong data entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK\n",
      "EU\n",
      "Iran\n"
     ]
    }
   ],
   "source": [
    "# we do it as well for Country\n",
    "names = list(df_not_nan[\"Country\"].unique())\n",
    "\n",
    "print_small_lens(names,thresh=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the small lenght countries are just initials, that will need to be dealth with later on, in the next notebook, that covers analysis and its data preparation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
