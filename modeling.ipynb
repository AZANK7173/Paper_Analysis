{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Modeling - Paper Themes from Digital Twins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare the papers and automatically decide with one of them have the similarities, the following steps need to me done:\n",
    "\n",
    "- Organize each paper in the dataset as one string to be compared between other string representations of papers\n",
    "- Create a CountVectorizer in order to transform each string in a vector \n",
    "- Compare each vector using cosine similarity \n",
    "- With the similarity results, rank the most similar ones to display them\n",
    "\n",
    "the following code was based in a older project that can be seen [here](https://github.com/turing-usp/locaturing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Material Type</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Country</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digital twin design for real-time monitoring -...</td>\n",
       "      <td>Others</td>\n",
       "      <td>Digital_twin, monitoring</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pervasive and Connected Digital Twins - A Visi...</td>\n",
       "      <td>Others</td>\n",
       "      <td>Digital_twin, Healthcare, monitoring</td>\n",
       "      <td>Italy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Digital Twin: Values, Challenges and Enablers ...</td>\n",
       "      <td>Others</td>\n",
       "      <td>Digital_twin, Hybrid Analysis and Modeling, Ma...</td>\n",
       "      <td>Norway, United States</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cyber-Physical Cloud Manufacturing Systems Wit...</td>\n",
       "      <td>Others</td>\n",
       "      <td>Digital_twin, MTconnect, cyberphysical cloud m...</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data‐driven physics‐based digital twins via a ...</td>\n",
       "      <td>Others</td>\n",
       "      <td>Digital_twin, data-model fusion, reduced-order...</td>\n",
       "      <td>Switzerland, United States</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name Material Type  \\\n",
       "0  Digital twin design for real-time monitoring -...        Others   \n",
       "1  Pervasive and Connected Digital Twins - A Visi...        Others   \n",
       "2  Digital Twin: Values, Challenges and Enablers ...        Others   \n",
       "3  Cyber-Physical Cloud Manufacturing Systems Wit...        Others   \n",
       "4  Data‐driven physics‐based digital twins via a ...        Others   \n",
       "\n",
       "                                             Keyword  \\\n",
       "0                           Digital_twin, monitoring   \n",
       "1               Digital_twin, Healthcare, monitoring   \n",
       "2  Digital_twin, Hybrid Analysis and Modeling, Ma...   \n",
       "3  Digital_twin, MTconnect, cyberphysical cloud m...   \n",
       "4  Digital_twin, data-model fusion, reduced-order...   \n",
       "\n",
       "                      Country Abstract  \n",
       "0                      Taiwan      NaN  \n",
       "1                       Italy      NaN  \n",
       "2       Norway, United States      NaN  \n",
       "3               United States      NaN  \n",
       "4  Switzerland, United States      NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data_clean.csv\", index_col='Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN values, in order to concat the string even with missing values\n",
    "df.fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String creation\n",
    "\n",
    "In order to create the string (our soup of words), we need to add the strings in each feature with the weights choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_commas(df):\n",
    "    '''\n",
    "    Replacing commas in order to do not be considered in the count vectorizer\n",
    "    '''\n",
    "\n",
    "    for column in df.columns:\n",
    "        df[column]=df[column].apply(lambda x: x.replace(\",\",\"\"))\n",
    "    \n",
    "    return df \n",
    "\n",
    "df = replace_commas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "def _create_soup_str(df: pd.DataFrame, columns: List[str],\n",
    "                pesos=(20, 30, 20, 20, 10)) -> str:\n",
    "    \"\"\"\n",
    "    function that creates a list of strings in form os a new column in the df, \n",
    "    the pesos are the weights of each column to be considered in the similarity. \n",
    "    In practice, the weights are the number of times each word will be repeted to \n",
    "    form the string. \n",
    "    \"\"\"\n",
    "    final_string = ''\n",
    "    for peso, column in zip(pesos, columns):\n",
    "        column_value = peso*df[column]\n",
    "        if isinstance(df[column].iloc[0], list):\n",
    "            column_value = df[column].apply(lambda row, peso=peso:' '.join(peso*row))\n",
    "        final_string += column_value + ' '\n",
    "    return final_string\n",
    "\n",
    "\n",
    "def create_soup(df: pd.DataFrame, columns=['Name', 'Material Type', 'Keyword', 'Country', 'Abstract'],\n",
    "                 pesos=(20, 30, 20, 20, 10)) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply the cration of the string soup gathering every dataframe and transform into one string\n",
    "    \"\"\"\n",
    "    df['soup'] = _create_soup_str(\n",
    "        df,\n",
    "        columns,\n",
    "        pesos\n",
    "    )\n",
    "\n",
    "    df['soup'] = df['soup'].apply(lambda x : \" \".join(x.split()))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=create_soup(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count vectorizer creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(df: pd.DataFrame) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Initiates the CountVectorizer and apply to the total string of the paper\n",
    "    \"\"\"\n",
    "    count = CountVectorizer(stop_words='english')\n",
    "    count_matrix = count.fit_transform(df['soup'])\n",
    "    cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "    return cosine_sim\n",
    "\n",
    "def reset_df_index(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    #reset indexes in order to organize the ranking of results for later\n",
    "    \"\"\"\n",
    "    df_process = df.reset_index()\n",
    "    indices = pd.Series(df_process.index, index=df_process['Name'])\n",
    "\n",
    "    return df_process, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = create_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process, indices = reset_df_index(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(df: pd.DataFrame, title: str,\n",
    "    cosine_sim: List[List[float]], indices: pd.Series) -> List[str]:\n",
    "    \"\"\"\n",
    "    with the cosine similarity results, sort the values and select the papers that are most \n",
    "    similar with the one entered in the data\n",
    "    \"\"\"\n",
    "    # Get the index of the Paper that matches the \"Name\" column\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all papers with the one choosen to be compared\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the Papers based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar ones \n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar papers\n",
    "    titles = df['Name'].iloc[movie_indices]\n",
    "    #return df.query('Name in @titles')\n",
    "    return titles.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of the 10 most similar papers: \n",
      " ['Industry 4.0 and the digital twin'\n",
      " 'A five-step approach to planning data-driven digital twins for discrete manufacturing systems'\n",
      " 'Sustainable Manufacturing Digital Twins: A Review of Development and Application'\n",
      " 'A taxonomy of digital twins' 'SEKAI\\xa0Digital\\xa0Twins Ltd'\n",
      " 'PTC Digital Twin'\n",
      " 'Digital twins for high-tech machining applications—a model-based analytics-ready approach'\n",
      " 'Untangling the requirements of Digital twin'\n",
      " 'Autonomous context-aware adaptive Digital Twins—State of the art and roadmap'\n",
      " 'Digital twin modeling']\n"
     ]
    }
   ],
   "source": [
    "recomend = get_recommendations(df_process,\n",
    "                    title=\"Pervasive and Connected Digital Twins - A Vision for Digital Health\",\n",
    "                    cosine_sim=cosine_sim,\n",
    "                    indices=indices\n",
    "                    )\n",
    "\n",
    "print(f\"list of the 10 most similar papers: \\n {recomend}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
